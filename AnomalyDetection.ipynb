{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AnomalyDetection.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "oe36JAHxpa5E"
      ],
      "mount_file_id": "1WkX3st5hXZbhA2FMrflI8p-dRwdEi3_e",
      "authorship_tag": "ABX9TyPfAavHwU9yy6LROUzkubmd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/francescogrillea/AnomalyDetectionTFLite/blob/main/AnomalyDetection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_jPsPao2miK"
      },
      "source": [
        "!cat ./drive/MyDrive/Colab*/anomaly_detection_data/res*"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i1mYVFxYSj7z"
      },
      "source": [
        "!rm ./drive/MyDrive/Colab*/anomaly_detection_data/res*"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vtqGVY5Gg_Xo"
      },
      "source": [
        "# Import e Costanti"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dRlm5Hkkf7QN"
      },
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "import time\n",
        "import logging\n",
        "import yaml\n",
        "\n",
        "cpu = os.popen('lscpu |grep \\'Model name\\'').read()\n",
        "ram_free = os.popen('free -h --si | awk  \\'/Mem:/{print $4}\\'').read()\n",
        "ram_total = os.popen('free -h --si | awk  \\'/Mem:/{print $2}\\'').read()\n",
        "\n",
        "logging.basicConfig(filename=\"./drive/MyDrive/Colab Notebooks/anomaly_detection_data/results.log\", level=logging.INFO, format='%(message)s')\n",
        "logging.info('CPU\\n\\t{}'.format(cpu))\n",
        "logging.info('RAM\\n\\t{} / {} free'.format(ram_free[:-1], ram_total[:-1]))"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8rDy5qTF8aEU"
      },
      "source": [
        "CONFIG_PATH = \"./drive/MyDrive/Colab Notebooks/anomaly_detection_data/config.yaml\"\n",
        "with open(CONFIG_PATH, \"r\") as f:\n",
        "    config = yaml.safe_load(f)\n",
        "\n",
        "PROJECT_PATH = config['PROJECT_PATH']\n",
        "ARCHITECTURE_TYPE = config['ARCHITECTURE_TYPE']\n",
        "CHANNEL_NAME = config['CHANNEL_NAME']\n",
        "\n",
        "DATASET_PATH = PROJECT_PATH+'Dataset/'\n",
        "TF_MODELS_PATH = PROJECT_PATH+'TF_Models/'+ARCHITECTURE_TYPE+'/'\n",
        "TFLite_MODELS_PATH = PROJECT_PATH+'TFLite_Models/'+ARCHITECTURE_TYPE+'/'\n",
        "RESULT_FILE_PATH = TFLite_MODELS_PATH+'results.yaml'\n",
        "\n",
        "try:\n",
        "  with open(RESULT_FILE_PATH, \"r\") as f:\n",
        "    results = yaml.safe_load(f)\n",
        "except FileNotFoundError:\n",
        "    results = {}\n",
        "\n",
        "if CHANNEL_NAME is None:\n",
        "  channels = [f for f in os.listdir(TF_MODELS_PATH)]\n",
        "  for c in channels:\n",
        "    b = c[:-3]\n",
        "    results[b] = {}\n",
        "else:\n",
        "  if not CHANNEL_NAME in results:\n",
        "    results[CHANNEL_NAME] = {}\n",
        "\n",
        "\n",
        "if not '_CPU' in results:\n",
        "  results['_CPU'] = cpu.strip()[21:]\n",
        "if not '_RAM' in results:\n",
        "  results['_RAM'] = ram_total.strip()\n",
        "\n",
        "\n",
        "logging.info('---------------------------------')\n",
        "logging.info('{}\\nArchitecture: {}\\nChannel: {}'.format(time.ctime(), ARCHITECTURE_TYPE, CHANNEL_NAME))\n",
        "\n",
        "def load_seed(channel_name):\n",
        "  with open(TF_MODELS_PATH+'seeds.log', 'r') as f:\n",
        "    for row in f.readlines():\n",
        "      if row.startswith(CHANNEL_NAME):\n",
        "        return row[4:]\n",
        "\n",
        "#load .h5 model\n",
        "def load_tf_model(channel_name):\n",
        "  if not channel_name.endswith('.h5'):\n",
        "    channel_name = channel_name+'.h5'\n",
        "  tf_model = keras.models.load_model(TF_MODELS_PATH+channel_name)\n",
        "  return tf_model\n",
        "\n",
        "#load dataset\n",
        "def load_dataset(channel_name):\n",
        "  if not channel_name.endswith('.npy'):\n",
        "    channel_name = channel_name+'.npy'\n",
        "  x = np.array([np.load(DATASET_PATH+'test/'+channel_name)])\n",
        "  y = np.array([])\n",
        "  return x,y\n",
        "\n",
        "def update_results():\n",
        "  with open(RESULT_FILE_PATH, 'w') as f:\n",
        "    yaml.dump(results, f)"
      ],
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "update_results()"
      ],
      "metadata": {
        "id": "H1DI5_VOVvh-"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oe36JAHxpa5E"
      },
      "source": [
        "# Prediction su TF Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KBE3XAsUpZr5",
        "outputId": "797f7157-44da-46ad-8796-0ff02235816a"
      },
      "source": [
        "#load dataset\n",
        "tf_input_data, tf_output_data = load_dataset(CHANNEL_NAME)\n",
        "\n",
        "#load model\n",
        "model = load_tf_model(CHANNEL_NAME)\n",
        "\n",
        "start_time = time.time()\n",
        "tf_output_data = model.predict(tf_input_data)\n",
        "delta_time = time.time()-start_time\n",
        "\n",
        "results[CHANNEL_NAME]['TF Model prediction time'] = delta_time\n",
        "results[CHANNEL_NAME]['TF Model predictions'] = tf_output_data[0].tolist()\n",
        "\n",
        "logging.info('TensorFlow prediction time: {}s'.format(delta_time))\n",
        "print('TensorFlow prediction time: {}s'.format(delta_time))"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow prediction time: 0.7707931995391846s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RpKpQ1nhioY6"
      },
      "source": [
        "# Conversione dei modelli da .h5 a .tflite"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QRfM_NG7imEd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7eaa4446-241a-4ba2-8862-bdb6698f4b91"
      },
      "source": [
        "channels = [f for f in os.listdir(TF_MODELS_PATH)]\n",
        "\n",
        "if not CHANNEL_NAME is None:\n",
        "  channels = [c for c in channels if c.startswith(CHANNEL_NAME)]\n",
        "\n",
        "n_channels = len(channels) \n",
        "counter = 0\n",
        "\n",
        "for channel in channels:\n",
        "  counter += 1\n",
        "  tflite_model_path = TFLite_MODELS_PATH+channel[:-3]+'.tflite'\n",
        "\n",
        "  if not os.path.isfile(tflite_model_path):\n",
        "    logging.info('Convert {} model from TensorFlow to TensorFlow Lite'.format(CHANNEL_NAME))\n",
        "    \n",
        "    start_time = time.time()\n",
        "    #load TF Model\n",
        "    tf_model = load_tf_model(channel)\n",
        "    #STATS- TF model size (in Kb)\n",
        "    tf_model_size = int(os.path.getsize(TF_MODELS_PATH+channel) / 1024)\n",
        "    results[channel[:-3]]['TF Model size'] = tf_model_size\n",
        "\n",
        "    #convert model to TensorFlow Lite\n",
        "    converter = tf.lite.TFLiteConverter.from_keras_model(tf_model)\n",
        "    converter.target_spec.supported_ops = [\n",
        "    tf.lite.OpsSet.TFLITE_BUILTINS, # enable TensorFlow Lite ops.\n",
        "    tf.lite.OpsSet.SELECT_TF_OPS # enable TensorFlow ops.\n",
        "  ]\n",
        "    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "    #WARNING:absl:Found untraced functions such as lstm_cell -> e' un warning che dipende da come Ã¨ stato salvato il modello, tuttavia non sembra esserci una precisa soluzione\n",
        "    tflite_model = converter.convert()\n",
        "\n",
        "    delta_time = time.time() - start_time\n",
        "\n",
        "    #generate TFLite model name and path\n",
        "    tflite_model_filename = channel[:-3]+'.tflite'\n",
        "    TFLite_MODEL_FILE = TFLite_MODELS_PATH+tflite_model_filename\n",
        "\n",
        "    #save TFLite model\n",
        "    with open(TFLite_MODEL_FILE, 'wb') as f:\n",
        "      f.write(tflite_model)\n",
        "    #STATS- .tflite model size (in Kb)\n",
        "    tflite_model_size = int(os.path.getsize(TFLite_MODEL_FILE) / 1024)\n",
        "    results[channel[:-3]]['TFLite Model size'] = tflite_model_size\n",
        "    results[channel[:-3]]['TFLite Model conversion time'] = delta_time\n",
        "\n",
        "    logging.info('Model '+channel[:-3]+' converted (from '+str(tf_model_size)+'Kb to '+str(tflite_model_size)+'Kb) in '+str(delta_time)+'s')\n",
        "    print(str(counter)+'/'+str(n_channels)+'- '+'Model '+channel[:-3]+' converted (from '+str(tf_model_size)+'Kb to '+str(tflite_model_size)+'Kb) in '+str(delta_time)+'s')"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpw8rvi_lv/assets\n",
            "1/1- Model A-2 converted (from 330Kb to 38Kb) in 10.760563611984253s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tEmmBFX12ECT"
      },
      "source": [
        "# Prediction su TFLite"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vNp9oM_B2G1z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "134acf9f-c6f5-4c50-ff63-c69815021c6c"
      },
      "source": [
        "#load dataset\n",
        "x_data, tflite_output_data = load_dataset(CHANNEL_NAME)\n",
        "\n",
        "interpreter = tf.lite.Interpreter(model_path=TFLite_MODELS_PATH+CHANNEL_NAME+'.tflite')\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "\n",
        "#preprocessing input data\n",
        "input_shape = input_details[0]['shape']     #[1, 1, 25]\n",
        "output_shape = output_details[0]['shape']   #[1, 10]\n",
        "\n",
        "\n",
        "interpreter.resize_tensor_input(input_details[0]['index'], [1, x_data.shape[1],25])\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "input_data = np.array(x_data, dtype=np.float32)\n",
        "interpreter.set_tensor(input_details[0]['index'], input_data)\n",
        "\n",
        "start_time = time.time()\n",
        "#run inference\n",
        "interpreter.invoke()\n",
        "tflite_output_data  = interpreter.get_tensor(output_details[0]['index'])\n",
        "delta_time = time.time() - start_time\n",
        "\n",
        "results[CHANNEL_NAME]['TFLite Model prediction time'] = delta_time\n",
        "results[CHANNEL_NAME]['TFLite Model predictions'] = tflite_output_data[0].tolist()\n",
        "results[CHANNEL_NAME]['Distance'] = (tf_output_data[0] - tflite_output_data[0]).tolist()\n",
        "\n",
        "logging.info('TensorFlowLite prediction time: {}s'.format(delta_time))\n",
        "print('TensorFlowLite prediction time: {}s'.format(delta_time))\n",
        "update_results()\n",
        "\n",
        "# Compare TF predictions with TFLite predictions\n",
        "try:\n",
        "  for y_tf, y_tflite in zip(tf_output_data[0], tflite_output_data[0]):\n",
        "    logging.info('{}\\t{}\\t{}'.format(y_tf, y_tflite, abs(y_tf-y_tflite)))\n",
        "    print('{}\\t{}\\t{}'.format(y_tf, y_tflite, abs(y_tf-y_tflite)))\n",
        "\n",
        "except NameError:\n",
        "  for val in tflite_output_data[0]:\n",
        "    print(val)"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlowLite prediction time: 1.5116493701934814s\n",
            "-0.05996561795473099\t-0.05363877862691879\t0.006326839327812195\n",
            "-0.0331600159406662\t-0.027672262862324715\t0.005487753078341484\n",
            "-0.008841438218951225\t-0.005508603528141975\t0.00333283469080925\n",
            "-0.014330176636576653\t-0.01231645792722702\t0.0020137187093496323\n",
            "-0.053852785378694534\t-0.053580496460199356\t0.0002722889184951782\n",
            "-0.11776037514209747\t-0.11875312775373459\t0.0009927526116371155\n",
            "-0.1684092879295349\t-0.16792014241218567\t0.0004891455173492432\n",
            "-0.23674480617046356\t-0.23825813829898834\t0.0015133321285247803\n",
            "-0.3546895384788513\t-0.35853102803230286\t0.003841489553451538\n",
            "-0.47840437293052673\t-0.4867083728313446\t0.008303999900817871\n"
          ]
        }
      ]
    }
  ]
}