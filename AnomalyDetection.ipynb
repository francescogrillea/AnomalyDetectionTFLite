{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AnomalyDetection.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1WkX3st5hXZbhA2FMrflI8p-dRwdEi3_e",
      "authorship_tag": "ABX9TyPLbwbiLVcsT2mSjIUJcCjb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/francescogrillea/AnomalyDetectionTFLite/blob/main/AnomalyDetection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_jPsPao2miK"
      },
      "source": [
        "!cat ./drive/MyDrive/Colab*/anomaly_detection_data/res*"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i1mYVFxYSj7z"
      },
      "source": [
        "!rm ./drive/MyDrive/Colab*/anomaly_detection_data/res*"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vtqGVY5Gg_Xo"
      },
      "source": [
        "# Import e Costanti"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dRlm5Hkkf7QN"
      },
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "import time\n",
        "import logging\n",
        "import yaml\n",
        "\n",
        "cpu = os.popen('lscpu |grep \\'Model name\\'').read()\n",
        "ram_free = os.popen('free -h --si | awk  \\'/Mem:/{print $4}\\'').read()\n",
        "ram_total = os.popen('free -h --si | awk  \\'/Mem:/{print $2}\\'').read()\n",
        "\n",
        "logging.basicConfig(filename=\"./drive/MyDrive/Colab Notebooks/anomaly_detection_data/results.log\", level=logging.INFO, format='%(message)s')\n",
        "logging.info('CPU\\n\\t{}'.format(cpu))\n",
        "logging.info('RAM\\n\\t{} / {} free'.format(ram_free[:-1], ram_total[:-1]))"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8rDy5qTF8aEU"
      },
      "source": [
        "CONFIG_PATH = \"./drive/MyDrive/Colab Notebooks/anomaly_detection_data/config.yaml\"\n",
        "with open(CONFIG_PATH, \"r\") as f:\n",
        "    config = yaml.safe_load(f)\n",
        "\n",
        "PROJECT_PATH = config['PROJECT_PATH']\n",
        "ARCHITECTURE_TYPE = config['ARCHITECTURE_TYPE']\n",
        "CHANNEL_NAME = config['CHANNEL_NAME']\n",
        "\n",
        "DATASET_PATH = PROJECT_PATH+'Dataset/'\n",
        "TF_MODELS_PATH = PROJECT_PATH+'TF_Models/'+ARCHITECTURE_TYPE+'/'\n",
        "TFLite_MODELS_PATH = PROJECT_PATH+'TFLite_Models/'+ARCHITECTURE_TYPE+'/'\n",
        "\n",
        "\n",
        "\n",
        "logging.info('---------------------------------')\n",
        "logging.info('{}\\nArchitecture: {}\\nChannel: {}'.format(time.ctime(), ARCHITECTURE_TYPE, CHANNEL_NAME))\n",
        "\n",
        "def load_seed(channel_name):\n",
        "  with open(TF_MODELS_PATH+'seeds.log', 'r') as f:\n",
        "    for row in f.readlines():\n",
        "      if row.startswith(CHANNEL_NAME):\n",
        "        return row[4:]\n",
        "\n",
        "#load .h5 model\n",
        "def load_tf_model(channel_name):\n",
        "  if not channel_name.endswith('.h5'):\n",
        "    channel_name = channel_name+'.h5'\n",
        "  tf_model = keras.models.load_model(TF_MODELS_PATH+channel_name)\n",
        "  return tf_model\n",
        "\n",
        "#load dataset\n",
        "def load_dataset(channel_name):\n",
        "  if not channel_name.endswith('.npy'):\n",
        "    channel_name = channel_name+'.npy'\n",
        "  x = np.array([np.load(DATASET_PATH+'test/'+channel_name)])\n",
        "  y = np.array([])\n",
        "  return x,y"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oe36JAHxpa5E"
      },
      "source": [
        "# Prediction su TF Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KBE3XAsUpZr5",
        "outputId": "a742c7ef-0670-44ee-9de8-6a9c4c76eb47"
      },
      "source": [
        "#load dataset\n",
        "tf_input_data, tf_output_data = load_dataset(CHANNEL_NAME)\n",
        "\n",
        "#load model\n",
        "model = load_tf_model(CHANNEL_NAME)\n",
        "\n",
        "start_time = time.time()\n",
        "tf_output_data = model.predict(tf_input_data)\n",
        "delta_time = time.time()-start_time\n",
        "\n",
        "logging.info('TensorFlow prediction time: {}s'.format(delta_time))\n",
        "print('TensorFlow prediction time: {}s'.format(delta_time))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow prediction time: 0.7587690353393555s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RpKpQ1nhioY6"
      },
      "source": [
        "# Conversione dei modelli da .h5 a .tflite"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QRfM_NG7imEd"
      },
      "source": [
        "channels = [f for f in os.listdir(TF_MODELS_PATH)]\n",
        "\n",
        "if not CHANNEL_NAME is None:\n",
        "  channels = [c for c in channels if c.startswith(CHANNEL_NAME)]\n",
        "  \n",
        "\n",
        "for channel in channels:\n",
        "  tflite_model_path = TFLite_MODELS_PATH+channel[:-3]+'.tflite'\n",
        "\n",
        "  if not os.path.isfile(tflite_model_path):\n",
        "    logging.info('Convert {} model from TensorFlow to TensorFlow Lite'.format(CHANNEL_NAME))\n",
        "    \n",
        "    start_time = time.time()\n",
        "    #load TF Model\n",
        "    tf_model = load_tf_model(channel)\n",
        "    #STATS- TF model size (in Kb)\n",
        "    tf_model_size = int(os.path.getsize(TF_MODELS_PATH+channel) / 1024)\n",
        "\n",
        "    #convert model to TensorFlow Lite\n",
        "    converter = tf.lite.TFLiteConverter.from_keras_model(tf_model)\n",
        "    converter.target_spec.supported_ops = [\n",
        "    tf.lite.OpsSet.TFLITE_BUILTINS, # enable TensorFlow Lite ops.\n",
        "    tf.lite.OpsSet.SELECT_TF_OPS # enable TensorFlow ops.\n",
        "  ]\n",
        "    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "    #WARNING:absl:Found untraced functions such as lstm_cell -> e' un warning che dipende da come Ã¨ stato salvato il modello, tuttavia non sembra esserci una precisa soluzione\n",
        "    tflite_model = converter.convert()\n",
        "\n",
        "    delta_time = time.time() - start_time\n",
        "\n",
        "    #generate TFLite model name and path\n",
        "    tflite_model_filename = channel[:-3]+'.tflite'\n",
        "    TFLite_MODEL_FILE = TFLite_MODELS_PATH+tflite_model_filename\n",
        "\n",
        "    #save TFLite model\n",
        "    with open(TFLite_MODEL_FILE, 'wb') as f:\n",
        "      f.write(tflite_model)\n",
        "    #STATS- .tflite model size (in Kb)\n",
        "    tflite_model_size = int(os.path.getsize(TFLite_MODEL_FILE) / 1024)\n",
        "\n",
        "    logging.info('Model '+channel[:-3]+' converted (from '+str(tf_model_size)+'Kb to '+str(tflite_model_size)+'Kb) in '+delta_time+'s')\n",
        "    print('Model '+channel[:-3]+' converted (from '+str(tf_model_size)+'Kb to '+str(tflite_model_size)+'Kb) in '+delta_time+'s')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tEmmBFX12ECT"
      },
      "source": [
        "# Prediction su TFLite"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vNp9oM_B2G1z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "236f1e2d-83ae-4b56-f10f-065acc95daab"
      },
      "source": [
        "#load dataset\n",
        "x_data, tflite_output_data = load_dataset(CHANNEL_NAME)\n",
        "\n",
        "interpreter = tf.lite.Interpreter(model_path=TFLite_MODELS_PATH+CHANNEL_NAME+'.tflite')\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "\n",
        "#preprocessing input data\n",
        "input_shape = input_details[0]['shape']     #[1, 1, 25]\n",
        "output_shape = output_details[0]['shape']   #[1, 10]\n",
        "\n",
        "\n",
        "interpreter.resize_tensor_input(input_details[0]['index'], [1, x_data.shape[1],25])\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "input_data = np.array(x_data, dtype=np.float32)\n",
        "interpreter.set_tensor(input_details[0]['index'], input_data)\n",
        "\n",
        "start_time = time.time()\n",
        "#run inference\n",
        "interpreter.invoke()\n",
        "tflite_output_data  = interpreter.get_tensor(output_details[0]['index'])\n",
        "delta_time = time.time() - start_time\n",
        "\n",
        "logging.info('TensorFlowLite prediction time: {}s'.format(delta_time))\n",
        "print('TensorFlowLite prediction time: {}s'.format(delta_time))\n",
        "\n",
        "\n",
        "# Compare TF predictions with TFLite predictions\n",
        "try:\n",
        "  for y_tf, y_tflite in zip(tf_output_data[0], tflite_output_data[0]):\n",
        "    logging.info('{}\\t{}\\t{}'.format(y_tf, y_tflite, abs(y_tf-y_tflite)))\n",
        "    print('{}\\t{}\\t{}'.format(y_tf, y_tflite, abs(y_tf-y_tflite)))\n",
        "\n",
        "except NameError:\n",
        "  for val in tflite_output_data[0]:\n",
        "    print(val)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlowLite prediction time: 1.8856532573699951s\n",
            "0.9981911182403564\t0.9981911182403564\t0.0\n",
            "0.9989597797393799\t0.9989597797393799\t0.0\n",
            "0.9989480376243591\t0.9989480376243591\t0.0\n",
            "0.9989720582962036\t0.9989720582962036\t0.0\n",
            "0.9992333054542542\t0.9992333054542542\t0.0\n",
            "0.9990507364273071\t0.9990507364273071\t0.0\n",
            "0.9991313219070435\t0.9991313219070435\t0.0\n",
            "0.9983036518096924\t0.9983036518096924\t0.0\n",
            "0.9991016983985901\t0.9991016983985901\t0.0\n",
            "0.9989663362503052\t0.9989663362503052\t0.0\n"
          ]
        }
      ]
    }
  ]
}