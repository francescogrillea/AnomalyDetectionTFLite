{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AnomalyDetection.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "RpKpQ1nhioY6",
        "tEmmBFX12ECT"
      ],
      "mount_file_id": "1WkX3st5hXZbhA2FMrflI8p-dRwdEi3_e",
      "authorship_tag": "ABX9TyNzKRF6vT07/sEbP+JpAfD8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/francescogrillea/AnomalyDetectionTFLite/blob/main/AnomalyDetection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_jPsPao2miK"
      },
      "source": [
        "!cat ./drive/MyDrive/Colab*/anomaly_detection_data/res*"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i1mYVFxYSj7z"
      },
      "source": [
        "!rm ./drive/MyDrive/Colab*/anomaly_detection_data/res*"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vtqGVY5Gg_Xo"
      },
      "source": [
        "# Import e Costanti"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dRlm5Hkkf7QN"
      },
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "import time\n",
        "import logging\n",
        "\n",
        "cpu = os.popen('lscpu |grep \\'Model name\\'').read()\n",
        "ram_free = os.popen('free -h --si | awk  \\'/Mem:/{print $4}\\'').read()\n",
        "ram_total = os.popen('free -h --si | awk  \\'/Mem:/{print $2}\\'').read()\n",
        "\n",
        "logging.basicConfig(filename=\"./drive/MyDrive/Colab Notebooks/anomaly_detection_data/results.log\", level=logging.INFO, format='%(message)s')\n",
        "logging.info('CPU\\n\\t{}'.format(cpu))\n",
        "logging.info('RAM\\n\\t{} / {} free'.format(ram_free[:-1], ram_total[:-1]))"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8rDy5qTF8aEU"
      },
      "source": [
        "#TODO read yaml file\n",
        "\n",
        "PROJECT_NAME = 'anomaly_detection'\n",
        "PROJECT_PATH = './drive/MyDrive/Colab Notebooks/anomaly_detection_data/'\n",
        "DATASET_PATH = PROJECT_PATH+'Dataset/'\n",
        "ARCHITECTURE_TYPE = 'LSTM_1L'\n",
        "TF_MODELS_PATH = PROJECT_PATH+'TF_Models/'+ARCHITECTURE_TYPE+'/'\n",
        "TFLite_MODELS_PATH = PROJECT_PATH+'TFLite_Models/'+ARCHITECTURE_TYPE+'/'\n",
        "CHANNEL_NAME = 'P-1'\n",
        "\n",
        "\n",
        "logging.info('---------------------------------')\n",
        "logging.info('{}\\nArchitecture: {}\\nChannel: {}'.format(time.ctime(), ARCHITECTURE_TYPE, CHANNEL_NAME))\n",
        "\n",
        "#load .h5 model\n",
        "def load_tf_model(channel_name):\n",
        "  if not channel_name.endswith('.h5'):\n",
        "    channel_name = channel_name+'.h5'\n",
        "  tf_model = keras.models.load_model(TF_MODELS_PATH+channel_name)\n",
        "  return tf_model\n",
        "\n",
        "#load dataset\n",
        "def load_dataset(channel_name):\n",
        "  if not channel_name.endswith('.npy'):\n",
        "    channel_name = channel_name+'.npy'\n",
        "  x = np.array([np.load(DATASET_PATH+'test/'+channel_name)])\n",
        "  y = np.array([])\n",
        "  return x,y"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oe36JAHxpa5E"
      },
      "source": [
        "# Prediction su TF Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KBE3XAsUpZr5",
        "outputId": "e3fe296e-541a-4141-c79e-d382d0983ee8"
      },
      "source": [
        "#load dataset\n",
        "tf_input_data, tf_output_data = load_dataset(CHANNEL_NAME)\n",
        "#load model\n",
        "model = load_tf_model(CHANNEL_NAME)\n",
        "\n",
        "start_time = time.time()\n",
        "tf_output_data = model.predict(tf_input_data)\n",
        "delta_time = time.time()-start_time\n",
        "\n",
        "logging.info('TensorFlow prediction time: {}s'.format(delta_time))\n",
        "print('TensorFlow prediction time: {}s'.format(delta_time))"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow prediction time: 0.7771511077880859s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RpKpQ1nhioY6"
      },
      "source": [
        "# Conversione dei modelli da .h5 a .tflite"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QRfM_NG7imEd"
      },
      "source": [
        "channels = [f for f in os.listdir(TF_MODELS_PATH)]\n",
        "\n",
        "if not CHANNEL_NAME is None:\n",
        "  channels = [c for c in channels if c.startswith(CHANNEL_NAME)]\n",
        "\n",
        "for channel in channels:\n",
        "  tflite_model_path = TFLite_MODELS_PATH+channel[:-3]+'.tflite'\n",
        "\n",
        "  if not os.path.isfile(tflite_model_path):\n",
        "    logging.info('Convert {} model from TensorFlow to TensorFlow Lite'.format(CHANNEL_NAME))\n",
        "    \n",
        "    start_time = time.time()\n",
        "    #load TF Model\n",
        "    tf_model = load_tf_model(channel)\n",
        "    #STATS- TF model size (in Kb)\n",
        "    tf_model_size = int(os.path.getsize(TF_MODELS_PATH+channel) / 1024)\n",
        "\n",
        "    #convert model to TensorFlow Lite\n",
        "    converter = tf.lite.TFLiteConverter.from_keras_model(tf_model)\n",
        "    converter.target_spec.supported_ops = [\n",
        "    tf.lite.OpsSet.TFLITE_BUILTINS, # enable TensorFlow Lite ops.\n",
        "    tf.lite.OpsSet.SELECT_TF_OPS # enable TensorFlow ops.\n",
        "  ]\n",
        "    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "    #WARNING:absl:Found untraced functions such as lstm_cell -> e' un warning che dipende da come Ã¨ stato salvato il modello, tuttavia non sembra esserci una precisa soluzione\n",
        "    tflite_model = converter.convert()\n",
        "\n",
        "    delta_time = time.time() - start_time\n",
        "\n",
        "    #generate TFLite model name and path\n",
        "    tflite_model_filename = channel[:-3]+'.tflite'\n",
        "    TFLite_MODEL_FILE = TFLite_MODELS_PATH+tflite_model_filename\n",
        "\n",
        "    #save TFLite model\n",
        "    with open(TFLite_MODEL_FILE, 'wb') as f:\n",
        "      f.write(tflite_model)\n",
        "    #STATS- .tflite model size (in Kb)\n",
        "    tflite_model_size = int(os.path.getsize(TFLite_MODEL_FILE) / 1024)\n",
        "\n",
        "    logging.info('Model '+channel[:-3]+' converted (from '+str(tf_model_size)+'Kb to '+str(tflite_model_size)+'Kb) in '+delta_time+'s')\n",
        "    print('Model '+channel[:-3]+' converted (from '+str(tf_model_size)+'Kb to '+str(tflite_model_size)+'Kb) in '+delta_time+'s')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tEmmBFX12ECT"
      },
      "source": [
        "# Prediction su TFLite"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vNp9oM_B2G1z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2dd91de9-d1c3-4f69-a976-659ba7ca75a5"
      },
      "source": [
        "#load dataset\n",
        "x_data, tflite_output_data = load_dataset(CHANNEL_NAME)\n",
        "\n",
        "interpreter = tf.lite.Interpreter(model_path=TFLite_MODELS_PATH+CHANNEL_NAME+'.tflite')\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "\n",
        "#preprocessing input data\n",
        "input_shape = input_details[0]['shape']     #[1, 1, 25]\n",
        "output_shape = output_details[0]['shape']   #[1, 10]\n",
        "\n",
        "\n",
        "interpreter.resize_tensor_input(input_details[0]['index'], [1, x_data.shape[1],25])\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "input_data = np.array(x_data, dtype=np.float32)\n",
        "interpreter.set_tensor(input_details[0]['index'], input_data)\n",
        "\n",
        "start_time = time.time()\n",
        "#run inference\n",
        "interpreter.invoke()\n",
        "tflite_output_data  = interpreter.get_tensor(output_details[0]['index'])\n",
        "delta_time = time.time() - start_time\n",
        "\n",
        "logging.info('TensorFlowLite prediction time: {}s'.format(delta_time))\n",
        "print('TensorFlowLite prediction time: {}s'.format(delta_time))\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "  Compare TF predictions with TFLite predictions\n",
        "\"\"\"\n",
        "\n",
        "try:\n",
        "  for y_tf, y_tflite in zip(tf_output_data[0], tflite_output_data[0]):\n",
        "    logging.info('{}\\t{}\\t{}'.format(y_tf, y_tflite, abs(y_tf-y_tflite)))\n",
        "    print('{}\\t{}\\t{}'.format(y_tf, y_tflite, abs(y_tf-y_tflite)))\n",
        "\n",
        "except NameError:\n",
        "  for val in tflite_output_data[0]:\n",
        "    print(val)"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlowLite prediction time: 2.0196874141693115s\n",
            "-0.5264647603034973\t-0.5172106027603149\t0.009254157543182373\n",
            "-0.560583770275116\t-0.5515011548995972\t0.009082615375518799\n",
            "-0.5594329833984375\t-0.5481669902801514\t0.011265993118286133\n",
            "-0.5435227751731873\t-0.5302269458770752\t0.01329582929611206\n",
            "-0.5413745045661926\t-0.5277824997901917\t0.013592004776000977\n",
            "-0.464438796043396\t-0.4500393569469452\t0.014399439096450806\n",
            "-0.4082942008972168\t-0.3928990960121155\t0.015395104885101318\n",
            "-0.29708144068717957\t-0.2845926880836487\t0.012488752603530884\n",
            "-0.1884109526872635\t-0.17934180796146393\t0.00906914472579956\n",
            "-0.18970084190368652\t-0.18388013541698456\t0.005820706486701965\n"
          ]
        }
      ]
    }
  ]
}